## Retrieval Augmented Generation

The video is not available yet. Please review the notebook, which is self-explanatory. #TODO

You will learn to implement Retrieval Augmented Generation (RAG) to enhance language models' responses by incorporating relevant context, covering:

- **LLM Context Limitations**: Understanding the constraints of context windows in large language models.
- **Retrieval Augmented Generation**: The technique of retrieving and using relevant documents to enhance model responses.
- **Embeddings**: How to convert text into numerical representations that are used for similarity calculations.
- **Similarity Search**: Finding the most relevant documents by calculating cosine similarity between embeddings.
- **OpenAI API Integration**: Using the OpenAI API to generate responses based on the most relevant documents.
- **Tourist Recommendation Bot**: Building a bot that recommends tourist attractions based on user interests using embeddings.
- **Next Steps for Implementation**: Insights into scaling the solution with a vector database, re-rankers, and improved prompts for better accuracy and efficiency.

Here are the links used in the video:

- [Jupyter Notebook](https://colab.research.google.com/drive/1x-g0kjktFkBcujJssKrx1xhZarsQA0ya)
- [`gte-large-en-v1.5` embedding model](https://huggingface.co/Alibaba-NLP/gte-large-en-v1.5)
- [Awesome vector database](https://github.com/mileszim/awesome-vector-database)
