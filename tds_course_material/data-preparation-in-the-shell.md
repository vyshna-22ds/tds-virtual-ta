## Data Preparation in the Shell

[![Data preparation in the shell](https://i.ytimg.com/vi_webp/XEdy4WK70vU/sddefault.webp)](https://youtu.be/XEdy4WK70vU)

You'll learn how to use UNIX tools to process and clean data, covering:

- `curl` (or `wget`) to fetch data from websites.
- `gzip` (or `xz`) to compress and decompress files.
- `wc` to count lines, words, and characters in text.
- `head` and `tail` to get the start and end of files.
- `cut` to extract specific columns from text.
- `uniq` to de-duplicate lines.
- `sort` to sort lines.
- `grep` to filter lines containing specific text.
- `sed` to search and replace text.
- `awk` for more complex text processing.

Here are the links used in the video:

- [Data preparation in the shell - Notebook](https://colab.research.google.com/drive/1KSFkQDK0v__XWaAaHKeQuIAwYV0dkTe8)
- [Data Science at the Command Line](https://jeroenjanssens.com/dsatcl/)
